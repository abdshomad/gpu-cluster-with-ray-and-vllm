services:
  # Ray Serve service (vLLM deployment)
  ray-serve:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: ray-serve
    runtime: nvidia
    environment:
      # NVIDIA GPU configuration
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
      # Prometheus and Grafana integration for Ray Dashboard
      # Note: RAY_GRAFANA_IFRAME_HOST is the URL accessible from the browser (host machine)
      # It should match the Grafana port exposed on the host
      RAY_PROMETHEUS_HOST: "http://prometheus:9090"
      RAY_GRAFANA_HOST: "http://grafana:3000"
      RAY_GRAFANA_IFRAME_HOST: "${RAY_GRAFANA_IFRAME_HOST:-http://localhost:13000}"
      # Ray configuration from .env
      RAY_ADDRESS: "${RAY_ADDRESS:-auto}"
      # Load all environment variables from .env and .secrets
      # Note: test-models-config.env can override with MODELS_CONFIG for multi-model testing
    env_file:
      - ../.env
      - ../.secrets
      - ../docker/test-models-config.env  # Add test config (can override MODEL_ID)
    ports:
      # Ray API port (configurable via .env)
      - "${RAY_API_PORT:-8000}:8000"
      # Ray Dashboard port (configurable via .env)
      - "${RAY_DASHBOARD_PORT:-8265}:8265"
      # Ray Metrics port for Prometheus scraping (default: 18080 to avoid conflicts)
      - "${RAY_METRICS_PORT:-18080}:8080"
    volumes:
      # Optional: Mount model cache directory
      - model_cache:/root/.cache/huggingface
      # Share Ray metrics directory with Prometheus
      - ray_metrics:/tmp/ray
      # Temporary directory for Ray (with cleanup on restart)
      - /tmp/ray-tmp:/tmp/ray-tmp
    networks:
      - gpu-cluster-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  # Prometheus - Metrics collection and storage
  prometheus:
    image: prom/prometheus:latest
    container_name: gpu-cluster-prometheus
    ports:
      # Prometheus web UI port (configurable via .env)
      - "${PROMETHEUS_PORT:-19090}:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
      # Mount Ray's metrics directory to access service discovery and config
      - ray_metrics:/tmp/ray:ro
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    depends_on:
      - ray-serve
    networks:
      - gpu-cluster-network
    restart: unless-stopped

  # Grafana - Metrics visualization
  grafana:
    image: grafana/grafana:latest
    container_name: gpu-cluster-grafana
    ports:
      # Grafana web UI port (configurable via .env)
      - "${GRAFANA_PORT:-13000}:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SECURITY_ALLOW_EMBEDDING=true
      # Enable anonymous access for auto-login (reads from default organization)
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
    depends_on:
      - prometheus
    networks:
      - gpu-cluster-network
    restart: unless-stopped

  # CheckMK - Enterprise monitoring with Prometheus integration
  checkmk:
    image: checkmk/check-mk-raw:latest
    container_name: gpu-cluster-checkmk
    ports:
      # CheckMK web UI port (configurable via .env)
      - "${CHECKMK_PORT:-15000}:5000"
      # CheckMK agent receiver port
      - "${CHECKMK_AGENT_PORT:-6556}:6556"
    volumes:
      - checkmk_data:/omd/sites
    environment:
      - CMK_SITE_ID=cmk
      - CMK_PASSWORD=${CHECKMK_PASSWORD:-admin}
    depends_on:
      - prometheus
    networks:
      - gpu-cluster-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/cmk/check_mk/login.py"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 240s

  # Nginx reverse proxy
  nginx:
    image: nginx:alpine
    container_name: gpu-cluster-nginx-proxy
    ports:
      # Nginx HTTP port (configurable via .env)
      - "${NGINX_HTTP_PORT:-80}:80"
      # Nginx HTTPS port (configurable via .env)
      - "${NGINX_HTTPS_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./webapp:/usr/share/nginx/html/webapp:ro
    depends_on:
      - ray-serve
      - prometheus
      - grafana
      - checkmk
    networks:
      - gpu-cluster-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "wget --quiet --tries=1 --spider http://localhost/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  gpu-cluster-network:
    driver: bridge

volumes:
  model_cache:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  ray_metrics:
    driver: local
  checkmk_data:
    driver: local

